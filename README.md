# Coding assignment on linking records from different data sources that I completed for class. I cannot share my code publicly but it can shared upon request. 

# Data Cleaning & Linkage

For this assignment you will be working with two data sets generated by different organizations.

One data set (`data/il-ppp.csv`) is a listing of Paycheck Protection Program Loans made during the pandemic to companies in Illinois.  ([Original Source](https://data.sba.gov/dataset/ppp-foia/resource/b327ff8c-3a76-4b10-a8b0-26d77aa2f896))

The second dataset is IL campaign finance data from OpenSecrets.org.  ([Original Source](https://www.opensecrets.org/resources/create/data.php)).  Since the size of the raw data is enormous, you've been provided with `data/il_opensecrets_orgs.csv`, which is a listing of all unique Org/City/Zip combinations found in the latest Illinois campaign finance data.

Since these datasets were built by different organizations they do not have common identifiers for the companies they reference.

For example:

```shell
# the grep command searches for a string (actually a regular expression) in a file
$ grep -i firebelly data/*.csv
data/il-ppp.csv:337604,1097828610,03/12/2021,507,PPS,FIREBELLY DESIGN CORPORATION,1402 N Western Ave,Chicago,IL,60622-1734,12/18/2021,Paid in Full,60,100,227215.0,227215.0,0.0,,48270,"JPMorgan Chase Bank, National Association",1111 Polaris Pkwy,COLUMBUS,OH,43240-2031,U,Y,N,Existing or more than 2 years old,Chicago,COOK,IL,60622-1734,IL-04,12.0,541430.0,White,Not Hispanic or Latino,1.0,227211.0,,,,,,Subchapter S Corporation,48270,"JPMorgan Chase Bank, National Association",COLUMBUS,OH,Female Owned,Non-Veteran,,228637.62,11/02/2021
data/il-ppp.csv:342714,3515887308,04/29/2020,507,PPP,FIREBELLY DESIGN CORPORATION,1402 N WESTERN AVE,CHICAGO,IL,60622,04/22/2021,Paid in Full,24,100,200275.0,190275.0,0.0,,48270,"JPMorgan Chase Bank, National Association",1111 Polaris Pkwy,COLUMBUS,OH,43240-2031,U,Y,N,Existing or more than 2 years old,CHICAGO,COOK,IL,60622-0001,IL-05,10.0,541430.0,White,Not Hispanic or Latino,1102.0,158998.0,,12500.0,,17675.0,,Subchapter S Corporation,48270,"JPMorgan Chase Bank, National Association",COLUMBUS,OH,Female Owned,Non-Veteran,,191973.94,03/25/2021
data/il_opensecrets_orgs.csv:886252,Firebelly Design,CHICAGO,60647
data/il_opensecrets_orgs.csv:1005715,Firebelly Design,CHICAGO,60647
```

This shows that each of these data sets includes this company,
but one refers to it as 'FIREBELLY DESIGN CORPORATION' and the other as
'Firebelly Design'.  The ID columns have nothing to do with one another,
since these data sets were built by different organizations.

These kinds of differences exist all over the data, and there is far too
much to match by hand, so we will need to use a probabilistic record
linkage approach to build connections between the two data sets.

## Process Overview

We will train an algorithm to classify pairs of entries as matches,
 non-matches, and possible matches.  The algorithm has several steps:

1. Pre-process each dataset, obtaining comparable lists of unique entity names with associated cities and zip codes.
2. Use provided pre-classified data to train a classifier.
3. Use the trained classifier on the full dataset to find high-confidence matches.

## Provided Files

Within the `linkage` directory you will find the following files:

* `clean.py` - Contains functions for loading the data and doing a bit of cleanup.
* `similarity.py` - Contains functions for computing similarity scores.
* `classifier.py` - Functions for building and using the classifier.
* `datatypes.py` - Provides potentially helpful constants and `namedtuples` for working with the data.
  * Note: You are not required to use all of these, but they may be helpful.

## Provided Data

`data/il-ppp.csv` - PPP Loan data for Illinois

This data has all of its original fields.  We will be using the following fields:

* `BorrowerName` - The name of the company that received the loan.
* `BorrowerCity` - The city where the company is located.
* `BorrowerZip` - The zip code where the company is located.

`data/il_opensecrets_orgs.csv` - OpenSecrets.org data for Illinois

This data has already been filtered a bit since there is a lot of it. You will find the following fields:

* `OrgName` - The name of an employer listed on a campaign finance report.
* `City` - The city where the donor was located.
* `Zip` - The zip code where the donor was located.

It is worth noting that the meaning of the city & zip fields also differs a bit from the PPP data.
In the PPP data, the city and zip fields refer to the location of the company that received the loan.  In the OpenSecrets data, the city and zip fields refer to the location of the donor.  We'll still be using these as potential hints for the classifier but it is important to understand your data as you work with it.

There are also two files that contain pre-classified data:

* `data/matches.csv` - A list of pairs of entries that are known to be matches.
* `data/non_matches.csv` - A list of pairs of entries that are known to be non-matches.

You'll use these pre-classified data to train your classifier.

## Part 1: Loading & Preparing The Data

We can make the following observations about the data:

* The case is inconsistent between the two data sets.
* The PPP data sometimes uses Zip+4 codes, while the OpenSecrets data does not.
* Some people are listed as "Self-Employed" in the OpenSecrets data, we can ignore these entries since they are not companies.

The first step in this process is to clean / normalize the data so it is ready for comparisons.

For Part 1, you will implement the `clean_ppp_data` and `clean_opensecrets_data` functions in `clean.py` to clean the data.

Their docstrings provide specifics on what needs to be done.

There are tests in `tests/test_clean.py` that you can run to check your work.

## Part 2: Generating Similarity Tuples

Even after cleaning the data there will be differences between the company and city names between the two data sets.

A common measure of similarity for strings is the *edit distance*.  The edit distance is the number of insertions, deletions, and substitutions needed to transform one string into another.

We'll be using the [Jaro-Winkler](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance) similarity to measure the similarity between two strings.

You will use the `jellyfish` library to compute the Jaro-Winkler similarity between two strings.
Given any two strings, the function `jellyfish.jaro_winkler_similarity` will return a number between 0 and 1 indicating the similarity between the two strings.

```python
>>> import jellyfish
>>> jellyfish.jaro_winkler_similarity('firebelly design', 'firebelly design')
1.0
>>> jellyfish.jaro_winkler_similarity('firebelly design', 'firebelly design, inc.')
0.9454545454545455
>>> jellyfish.jaro_winkler_similarity('firebelly design', 'potbelly sandwiches')
0.66457336523126
```

When Jaro-Winkler scores it is helpful to divide them into three categories:

* High similarity (0.95-1.0)
* Medium similarity (0.8-0.95)
* Low similarity (0.0-0.8)

In practice you would adjust these thresholds to suit your needs. For this project we will use these thresholds.

We will apply this similarity measure to the company and city names in the two data sets.  We will also do a direct comparison of the zip codes.  That means that for any two entries in the two data sets, we will have three similarity scores:

* Company name similarity (`"high", "medium", "low"`)
* City name similarity (`"high", "medium", "low"`)
* Zip code similarity (`True or False`)

We'll call this our *similarity tuple*.  If you look at `datatypes.py` you will see that we have a `SimilarityTuple` `namedtuple` that you can use to represent these values if you wish.

For part 2, you will be writing the function `calculate_similarity_tuple` in `similarity.py`. This function takes two entries from the two data sets and returns a similarity tuple.

For two hypothetical entries:

```python
firebelly = ("firebelly design", "chicago", "60647")
firebelly_llc = ("firebelly design, llc", "chicago", "60648")
potbelly = ("potbelly sandwiches", "chicago", "60647")

>>> calculate_similarity_tuple(firebelly, potbelly)
("low", "high", True)
>>> calculate_similarity_tuple(firebelly, firebelly_llc)
("high", "high", False)
```

## Part 3: Training the Classifier

For this portion of the assignment you will be implementing the function:

```python
def train_classifier(max_false_positives, max_false_negatives):
```

There are 18 possible similarity tuples ranging from `("high", "high", True)` to `("low", "low", False)`. Our next step is to train a classifier to determine the probability of a match given a similarity tuple.

Our classifier will need to be able to map each possible similarity tuple to one of our labels: "match", "non-match", or "possible match".

To do this, we will use already-labeled data to train the classifier.

The files `data/matches.csv` and `data/non-matches.csv` contain hand-labeled match and non-match data.

Each file consists of two columns: `ppp_id` and `opensecrets_entry_id`. These are the ids of the entries in the PPP and OpenSecrets data sets that were labeled as a match or non-match.  Pairs in `matches.csv` are labeled as matches and files in `non-matches.csv` are labeled as non-matches.

Using this data, we can compute probabilities for each similarity tuple that it is a match or non-match.

For example, if you know that the pair (537, 310398) was a match you would
find the similarity tuple for that pair and increment the count of matches for that tuple.  Likewise, knowing that the pair (550, 312239) is a non-match would increment the count of non-matches for their associated similarity tuple.

**Note: At this step, you should only be computing similarity tuples for the pairs in `matches.csv` and `non-matches.csv`.  You should not be computing similarity tuples for the entire data set as that will take an incredibly long time.**

Once you have gone through all the matches, you can convert your counts to probabilities of a match for each tuple.

Let's call these probabilities `m(t)` and `n(t)` where `t` is a similarity tuple and `m(t)` is the probability that `t` is a match and `n(t)` is the probability that `t` is a non-match.

Compute two dictionaries, `match_probabilities` and `non_match_probabilities` corresponding to `m(t)` and `n(t)` above.  Each dictionary should have a key for each possible similarity tuple and a value that is the probability of a match or non-match given that similarity tuple.

### Partitioning tuples into match, non-match, and possible match

The goal of this step is to compute a dictionary that matches each similarity tuple to a label.

How do we decide which label to assign to a similarity tuple?

This depends on our willingness to have false positives and false negatives.  For each of these error types, our classifier will take an "acceptable error rate" as input.

Let's call these `max_false_positives` and `max_false_negatives`.

1. For any tuple `t` where `m(t) == n(t) == 0`, assign the label "possible match".  *We don't have any data in our training set for these tuples, so we can't make a decision about them.*

2. Order the remaining tuples by their likelihood of being a match. You can do this by sorting the tuples by `m(t)/n(t)`.  If a tuple has `n(t) == 0`, you can put it at the front of the list. *This gives a ranked order of how likely a tuple is to be associated with a match.  If the tuple has never been associated with a non-match, it is very likely to be a match and pushed to the front of our order.*

To help with this step we've provided a function `classifier.sort_similarities` that will sort the tuples for you.

3. You will wind up with a list of tuples along with their match and non-match probabilities. For example:

```python
[
    (("high", "high", True), 0.9, 0),
    (("high", "high", False), 0.8, 0),
    (("high", "medium", True), 0.8, 0.01),
    (("high", "medium", False), 0.8, 0.05),
    (("high", "low", True), 0.8, 0.1),
    (("high", "low", False), 0.8, 0.2),
    (("medium", "medium", True), 0.55, 0.2),
    (("medium", "medium", False), 0.55, 0.3),
    (("medium", "low", False), 0.6, 0.33),
    (("medium", "high", True), 0.6, 0.35),
    (("medium", "high", False), 0.6, 0.4),
    (("medium", "low", True), 0.5, 0.5),
    (("low", "high", True), 0.2, 0.75),
    (("low", "high", False), 0.2, 0.8),
    (("low", "medium", False), 0.1, 0.87),
    (("low", "medium", True), 0.1, 0.89),
    (("low", "low", False), 0.05, 0.77),
    (("low", "low", True), 0.05, 0.79),
]
```

The next step is to use this list to build a dictionary that maps each similarity tuple to a label (`MATCH`, `NON_MATCH`, `MAYBE_MATCH`).

You will do this by starting at the beginning of the list and adding tuples to the `matches` category until it would cause the false positive rate to exceed `max_false_positives`.  (**Note: Do not exceed max false positives, you will need to stop before adding the tuple that would cause you to exceed that threshold.**)

Then, starting at the end of the list, you will add tuples to the `non_matches` category until it would cause the false negative rate to exceed `max_false_negatives`.  (**Note: Like above, do not exceed max false negatives, you will need to stop before adding the tuple that would cause you to exceed that threshold.**)

Finally, you will be left with a list of tuples that are neither matches nor non-matches.  These are your `MAYBE_MATCH` tuples.

#### Note: Overlap

It is possible to select a `max_false_positives` and `max_false_negatives` that will cause the `matches` and `non_matches` lists to overlap.  Since matching data is preferable, you should prefer to have a `matches` list that is as large as possible.

That means that if a tuple would be eligible for both the `matches` and `non_matches` lists, you should add it to the `matches` list and not the `non_matches`. If your implementation handles matches first, you might not need to do anything special to handle this case but be aware of it.

## Part 4: Generating Linked Data

You now have a classifier that maps similarity tuples to labels.

To determine if two arbitrary records are a match, you can calculate their similarity tuple and look up the label in your classifier.

If time was not a concern, you could compare every record in the PPP data to every record in the campaign finance data and generate a linked data set.

In practice, this means comparing ~40000 records to ~100000 records, which is still 4 billion comparisons.

This is a very time consuming operation with as much data as we have, so we will support blocking to speed things up.

Blocking is a technique that allows us to reduce the number of comparisons we need to make by grouping similar records together and only comparing among like blocks.

For the final task, you will implement `classifier.find_matches`, a function that will compare records in the PPP data to records in the campaign finance data and return a list of matches.

It should:

1. Read in the PPP data and the campaign finance data using the `read_data` function you wrote in Part 1.
2. Build a classifier using the `build_classifier` function you wrote in Part 3.
3. Compare each record in the PPP data to each record in the campaign finance data to obtain a match classification ("match", "non-match", or "possible match").  This comparison can be done by obtaining a similarity tuple for each pair you are comparing and then using the classifier to match the tuple to a label.
    * If `block_on_city` is `True`, you should only compare records that have the exact same city. This blocking needs to happen *before* similarity tuples are computed to be effective.
    * If `block_on_city` is `False`, you should compare all records.
    * Because this function takes a long time to run, it takes a `max_matches` parameter.  You should stop comparing records once you have found `max_matches` matches.  This is useful for testing your code.

## Grading / Tips

In addition to correctness, we will be focusing on good design when grading this assignment.  Pay particular attention to code reuse and readability.  Making use of the data types provided will help with readability.

You'll likely wind up wanting to break your code into several smaller functions. Consider where this makes sense, especially if you find yourself wanting the output of a particular portion-- that might be a good candidate for a function.  (You might even consider writing your own tests for these functions!)

## About the Data

PPP Loan Data from SBA.gov: <https://data.sba.gov/dataset/ppp-foia/resource/b327ff8c-3a76-4b10-a8b0-26d77aa2f896>

Campaign Finance data from OpenSecrets.org

OpenSecrets data is under a [Creative Commons Attribute Non-Commercial Share Alike](http://creativecommons.org/licenses/by-nc-sa/3.0/) license.

Data Last Updated January 2023

## Acknowledgements

This assignment was adapted from an earlier assignment designed and written by Amitabh Chaudhary.

